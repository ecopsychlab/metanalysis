---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# metanalysis

<!-- badges: start -->
[![GitHub issues](https://img.shields.io/github/issues/ecopsychlab/metanalysis)](https://github.com/ecopsychlab/metanalysis/issues)
[![GitHub pulls](https://img.shields.io/github/issues-pr/ecopsychlab/metanalysis)](https://github.com/ecopsychlab/metanalysis/pulls)
[![R BiocCheck](https://github.com/ecopsychlab/metanalysis/actions/workflows/test.yml/badge.svg)](https://github.com/ecopsychlab/metanalysis/actions/workflows/test.yaml)
<!-- badges: end -->
The goal of metanalysis is to provide a convenient interface to manage and 
analyse multiple data sets. 

## Installation

You can install the development version of metanalysis from 
[GitHub](https://github.com/) with:

``` r
# install.packages("remotes")
remotes::install_github("ecopsychlab/metanalysis")
```

## Imaginary Usecase

This is a basic example which shows you how to solve a common problem:

```{r examplea}
library(metanalysis)
# We have a list of tables
x <- split.data.frame(mtcars, rep(LETTERS[seq_len(4)], each = 8))
x

```

```{r exampleb}
# Let's first prepare a nested folder structure to keep our tables: 

create_dataset(x, "demo_folder")

# Confirm that the files are now written: 
list.files("demo_folder", full.names = TRUE, recursive = TRUE)
```

meta_study object could be the main user-oriented interface, for instance to get
summary statistics across data sets. 

```{r meta-studya}

x <- meta_study("demo_folder")
x

```

Maybe some information could be collected like this: 

```{r meta-studyb}
x@study_data

```

```{r examplec}
# We can treat our folder as a data base and open it using the arrow library: 
library(arrow)

# we can wrap arrow::open_dataset by calling it like this: 

arrow::open_dataset(x@folder_name)

# I should ensure this doesn't mess with arrow performance. 

```

From there: 
- harmonize metadata - see `schema` documentation of arrow

- define analyses - see `arrow::register_scalar_function()` - looks really nice,
  but almost certainly would require some nice wrapping for our target audience.

- alternate input methods

- do we want to automatically create a reproducible repository for the analysis?

